\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{\theenumi)}

\title{Database Design}
\author{Joshua Harrison}
\date{\today}

\begin{document}
\maketitle

\section{Relational Design}

\subsection{Relationl schema design}
This section will discuss some of the noteworthy descisions taken in the design of the relational schema for the given problem domain.
The full SQL for the relational schema can be seen in \emph{appendix 1.1}. Note: PostgreSQL 9.6 is used for all DML and DDL defined in this document. The online SQL compiler https://rextester.com was used to validate the schema and its constraints.

\subsubsection{Types}
The schema defines two custom enum types, namely  `ISO3166\_ALPHA2' (based on the ISO3166 standard), and `AQUISITION\_STATUS'. It is worth noting that `ISO3166\_ALPHA2' is loaded with a subset of the full standard as this is fit for the purpose of our data model.

The AQUISITION\_STATUS status enum is implement by the \emph{status} column in the \emp{acquisition} table, and the ISO3166\_ALPHA2 enum is implemented diretly by the \emp{country} table as well as all tables which contain a foriegn key to this (\emph{company}, \emph{founder}).

The use of Enums is advantegous as it provides a means of implict santisation to the tables that implement these types. For example it means an \emph{acquisition} instance could never be created with an undeseriable status (i.e a status outside the domain of strings defined by the enum). The same is true of the ISO3166\_ALPHA2 implemention, through it we can be assured the quality of the country code in the database is acurate. Considering Date's  oberservation [REF - Date] that a table can be thought of as a predicate for which each row is a true proposition, custom data types enable use to constrain the domain of the predicate to only relevant values. For example, the ISO3166\_ALPHA2 implemented in this model it would be impossible to enter a country with the values `Norway', `NO'. This is desireable in this model world as we are only interested in modelling companies and founders that are in the domain of the ISO3166\_ALPHA2 custom type.

It should be noted that the tuple (`Norway', `CN') would be a valid entry into the country table. We can verify that this record is false as per the ISO3166 standard [REF ISO3166], however there is nothing wrong with it from the data storage level. Therefore although implementing the custom type has helped with integrity, it has not guarenteed the quality of the data. To frame ths in the context of propositional logic as prescribed by Date; is possible for our schema to record false propositions. Dropping the country table altogether and extending the SO3166\_ALPHA2 type to include a country name and code tuple would therefore be an improvement that could be made to this model if we wanted to introduce more rigour and reduce the potential such inaccurracies.

\subsubsection{Relational Schema Design}
For the given problem the following schema has been defined. \\

\begin{verbatim}
--PostgreSQL 9.6

CREATE TYPE ISO3166_ALPHA2 AS ENUM ( `DE', `FR', `GB', `US',
                                      `JP', `CN');


CREATE TYPE AQUISITION_STATUS AS ENUM ( `announced' `completed',
                                        `failed');

DROP TABLE IF EXISTS country CASCADE;
CREATE TABLE country ( name varchar (255) NOT NULL,
code ISO3166_ALPHA2 NOT NULL, PRIMARY KEY (code));


DROP TABLE IF EXISTS company;
CREATE TABLE company ( id serial, name varchar (255) NOT NULL,
founded date NOT NULL, country_code ISO3166_ALPHA2 NOT NULL,
parent_company_id int DEFAULT NULL,
-- need to make this an int not a serial to allow nulls
 -- Constraints
 PRIMARY KEY (id), CONSTRAINT company_name_country UNIQUE (name,
                                                   country_code),
                      FOREIGN KEY (country_code)
                      REFERENCES country (code),
                      FOREIGN KEY (parent_company_id)
                      REFERENCES company (id));


CREATE TABLE founder ( id serial, firstname varchar (255) NOT NULL,
                      lastname varchar (255) NOT NULL,
                      dob date NOT NULL,
                      country_of_origin ISO3166_ALPHA2 NOT NULL,
                      PRIMARY KEY (id),
                      FOREIGN KEY (country_of_origin)
                      REFERENCES country (code));


CREATE TABLE founder_companies( founder_id serial, company_id serial,
                               FOREIGN KEY (founder_id)
                               REFERENCES founder (id),
                               FOREIGN KEY (company_id)
                               REFERENCES company (id));


CREATE TABLE acquistion ( parent_company_id int NOT NULL,
                        child_company_id int NOT NULL,
                        status AQUISITION_STATUS,
                        price_usd NUMERIC DEFAULT NULL,
                        announced_date DATE NOT NULL,
                        completion_date DATE DEFAULT NULL,
                        FOREIGN KEY (parent_company_id)
                        REFERENCES company (id),
                        FOREIGN KEY (child_company_id)
                        REFERENCES company (id));

\end{verbatim}

\subsection{Normalisation}
A relational schema can be said to be compliant to BCNF if for all of its functional dependencies (x $\Rightarrow$ y) if one of the following statements is true: \\\\
1) y is a subset of x (trival functional dependency) \\
2) x is a superkey (A subset of a candidate key for the relation). \\
Given this defintion and with the non-trivial functional dependcies highlighted below, we can judge that this schema is compliant to BCNF.

\subsubsection{Company}

id $\Rightarrow${\{name, founded, country\_code, parent\_company\_id\}} \\
\{{name, country\_code\}} $\Rightarrow$ {\{founded, parent\_company\_id, id\}} \\

\\ N.B. name and founded seems like a potential functional dependency, but note that in this schema name and country code form a composite unique constraint. That is to say that multiple companies with the same name can exist in the reltaion, provided they are in different countries. Hence functional dependencies with the \{{name, countrycode\}} tuple on the left side do hold, but those with \{{name, founded\}} do not.

The \{{name, founded\}} tuple is candidate key. Had this been implemented as a composite primary key there would have been no requirement for the additional `id' attribute, however as this key is used in multiple places as a foreign key to other tables (including the self reference in this table), it is more efficient to use an id field than a composite of two string column. x is a candidate key and therefore a superkey, hence this table does comform to BCNF. (https://www.vertabelo.com/blog/technical-articles/boyce-codd-normal-form-bcnf).

\subsubsection{Founder}
id $\Rightarrow$ \{{firstname, lastname, dob, country\_of\_origin\}}\\

The only functional dependency present is the base dependency that all columns are functionally dependent on the `id' primary key. Whilst on first glance it appears that other dependencies may exist such as \\\\
\{{firstname, lastname\}} $\Rightarrow$ \{{dob, country\_of\_origin\}}\\\\
these dependencies may hold for some states of the relation (or \emph{relational variable} - (JOSH - ref date), but as there are no unique constraints on any of these attributes, it is possible (if unlikely) to have founders with the same name, date of birth and country of origin in the relation (just as it is in the real world).

x is a primary key and therefore a superkey, hence this FD is BNCF compliant.

\subsubsection{Acquisition}
\{{parent\_company\_id, child\_company\_id\, announced\_date}\} $\Rightarrow${\{status, completion\_date}\} \\

This functional dependencies allows for historised records in the relation. Assuming that a parent company does not announce an attempted acquisition with the same child company more than once on the same day, if we know the attributes on the left side of the dependency we can always deduce the status and completion date of the accquisition. This enables historisation, as a company could make multiple failed attempts to acquire another before they finally are successful.

x is a candidate key and therefore a superkey, hence this table is compliant to BCNF.

\subsubsection{Founder\_companies}
No functional dependencies as this is a many to many join table, i.e a company can have many founders, and a founder can found many companies.

\subsection{Constraints}
The following constraints are expressed using Relational Calculus (RC) and then again in SQL.
\begin{enumerate}

  \item\label{part1}  RC:
 \begin{multline*}
   \{{id \mid \exists \ name, founded, country\_code, \\
   parent\_company\_id, (company(id, name, \\
   founded, country\_code, parent\_company\_id) \land \ id = parent\_company\_id)\}}
 \end{multline*}
 SQL:
 \begin{verbatim}
  ALTER TABLE company ADD CONSTRAINT not_own_parent
  CHECK (id != parent_company_id);
 \end{verbatim}

\item\label{part1}  RC:
  \begin{multline*}
  \{{(parent\_company\_id,  child\_company\_id) \mid \exists \ status, price\_usd, \\ announced\_date, completion\_date, (acquistion(parent\_company\_id, \\ child\_company\_id, status, price\_usd, announced\_date, completion\_date) \\ \land \ completion\_date < announced\_date )\}}
  \end{multline*}
 SQL: \begin{verbatim}
 ALTER TABLE acquisition ADD CONSTRAINT check_completion_date
 CHECK (completion_date >= announced_date);
 \end{verbatim}


 \item\label{part1}
 \begin{multline*}
 \{{(parent\_company\_id, child\_company\_id) \mid \exists \ status, price\_usd, announced\_date, \\
 completion\_date, (acquistion(parent\_company\_id, child\_company\_id, status, \\
 price\_usd, announced\_date, completion\_date)\\
 \land status \ \lnot \  `failed' \\
 \ \lor \ (status = `failed' \land completion\_date = completion\_date)  \}}
\end{multline*}
 \\ n.b. `completion\_date = completion\_date' is a means for asserting that the completion\_date value is not NULL. \\
  SQL: \begin{verbatim}
ALTER TABLE acquisition ADD CONSTRAINT CONSTRAINT
check_no_failed_completion_dates CHECK (
        status <> `failed'
        or status = `failed' AND (completion_date IS NULL))
);
\end{verbatim}


 \item\label{part1}
 \begin{multline*} RC:
 \{{id \mid \exists \ name, founded, country\_code, \\
 parent\_company\_id,  parent\_company\_id, child\_company\_id, \\
 status, price\_usd, announced\_date, completion\_date, \\
 (company(id, name, founded, country\_code, \\
 parent\_company\_id,  parent\_company\_id) \\
 \ \land \ acquistion(parent\_company\_id, child\_company\_id, \\
 status, price\_usd, announced\_date, completion\_date) \\
 \ \land \ announced\_date <  founded  \}}
 \end{multline*}
   SQL: This check cannot be enforced using SQL as a pure constraint, as it opporates on values from multiple tables in the schema. It is possible to make use of a trigger which is called on row update to check for the constraint and raise an exception should a write request attempt be found to be in violation. A potential implemention is:  \begin{verbatim}

   CREATE FUNCTION acquisition_date_constraint() RETURNS trigger
   AS $acquisition_date_constraint$
    BEGIN
        IF NEW.announced_date < (SELECT founded FROM company
        WHERE id = NEW.child_company_id) THEN
            RAISE EXCEPTION
            `% Acquistion cannot be announced before
            company founded!', NEW.announced_date;
        END IF;

        RETURN NEW;
    END;
$acquisition_date_constraint$ LANGUAGE plpgsql;

-- Run the trigger whenever a row is inserted
-- or updated to acquisitions
CREATE TRIGGER acquisition_date_constraint
BEFORE INSERT OR UPDATE ON acquistion
    FOR EACH ROW EXECUTE PROCEDURE acquisition_date_constraint();
   \end{verbatim}
\end{enumerate}
Here the custom function \emph{acquisition\_date\_constraint} is defined to return a trigger. The trigger then provides the SQL to constrain the announced date not preceding the founded date of an acquired company, raising an exception if a violation occurs. The function is set to be called on any insert or update to the acquisition table. \\
(https://www.postgresql.org/docs/9.1/plpgsql-trigger.html#PLPGSQL-TRIGGER-EXAMPLE)

\section{Relations - Relational Calculus \& Algebra}
All of the queries in this section are expressed using Relational Algebra (RA), except for \emph{query a} is expressed using Relational Calculus (RC).
 \begin{enumerate}

 \item\label{part1}\begin{multline*}
 \{{id \mid \exists \ name, founded, country\_code, parent\_company\_id, \\ (company(id, name, founded, country\_code, parent\_company\_id) \\
  \land \ founded \ > \ `1999-12-31')\}}
 \end{multline*}
  \item\label{part1}\begin{multline*}
  \pi \ id (\sigma \ country\_code = `US' \ \lor country\_code = `GB' (company))
 \end{multline*}

  \item\label{part1}\begin{displaymath}
  \pi \ parent\_company\_id (\sigma status \ = `completed' (acquistion))
 \end{displaymath}
 n.b. The SQL equivolent of this query (see \emph {section 3}) uses the DISTINCT operator to remove duplicates, as RA is based on set theory this is not neccassary here.

  \item\label{part1}\begin{multline*} \pi \ founder\_id (\sigma founder\_id \geq 3 (founder\_id \ \\
  g \ count (founder\_id) (founder\_companies))
 \end{multline*}
 n.b. here the aggregate opperator \emph{g} is used to count over the occurances of each founder\_id in the relational. This aggregate can then be selected over.
  \item\label{part1}\begin{multline*}
  \pi \ child\_company\_id (f \bowtie c \ with (f := \\
  (\pi \ child\_company\_id, announced\_date (\sigma \ status = `failed' (acquistion))) \\
  c := (\pi \ child\_company\_id, completion\_date \\
  (\sigma \ status = `completed' (acquistion)))
  ) \\
  \sigma completion\_date > announced\_date)
 \end{multline*}
 In this query we select all companies with a failed acquisition and completed acuisitions and name the resulting relationals \emph{f} \& \emph{c} respectively using the \emph{with} operator. In both relations the \emph{child\_company\_id} and is kept, within \emph{f} the \emph{announced\_date} attribute is kept, and within {c} the \emph{completion\_date} attribute is kept. The rest of the fields are projected away. The relations are then joined using a natural join which utalises the fact that both relations have a \emph{child\_company\_id} attribute.We can then compare the \emph{completion\_date} of \emph{c} to the \emph{announced\_date} of \emph{f} to select only those in which the completed acquistion occurred after the failed attempt.

 It is worth noting that this query assumes that the acquistions are announced and resolved (i.e. fail or complete) in contiguous mannor in respect of their annnounced dates. The schema does not record the \emph {failed\_date} for failed acquisitions. Such an addition would make this query more accurate as the completion and failed dates could be directly compared, however this would affect the database design as if the attribute were to be added to the acquisitions relation then addtional functional dependencies would be introduced which would cause third normal form (3NF) violations. For example, \{{anounced\_date, status, parent\_company\_id, child\_company\_id }\} $\Rightarrow$ \{{completion\_date, failed\_date}\} or simply \{{completion\_date $\Leftrightarrow$ failed\_date}\}. Both of these examples are 3NF violations and as both introduce functional dependencies between non-key attributes.

  \item\label{part1} This query is not expressable in RA or RC due to the lack of a native \emph{limit} function.
  \item\label{part1} This query is not expressable in RA or RC due to the lack of recurrsion in the query languages.
  \end{enumerate}



\section{SQL}
\begin{enumerate}

 \item\label{part1}\begin{verbatim}SELECT id
FROM company
WHERE founded > `1999-12-31';\end{verbatim}

  \item\label{part1}\begin{verbatim}SELECT id
FROM company
WHERE country_code IN (`UK', `US');\end{verbatim}
  \item\label{part1}\begin{verbatim}SELECT distinct(parent_company_id)
FROM acquistion
WHERE status = `completed';\end{verbatim}
  \item\label{part1}\begin{verbatim} SELECT founder_id,
       COUNT (founder_id)
FROM founder_companies
GROUP BY founder_id HAVING COUNT(founder_id) >= 3;\end{verbatim}
  \item\label{part1}\begin{verbatim}SELECT f.child_company_id
FROM
  (SELECT *
   FROM acquistion
   WHERE status = `failed')f
JOIN
  (SELECT *
   FROM acquistion
   WHERE status = `completed')c
   ON c.child_company_id = f.child_company_id
WHERE c.completion_date > f.failed_date;\end{verbatim}
  \item\label{part1}\begin{verbatim}SELECT founder_id,
       count(founder_id)
FROM founder_companies
GROUP BY founder_id
ORDER BY count(founder_id) DESC LIMIT 10 ;\end{verbatim}
  \item\label{part1}\begin{verbatim}WITH RECURSIVE comp AS
  (SELECT parent_company_id,
          id,
          name
   FROM company
   WHERE name = `Tesla'
   UNION SELECT c.parent_company_id,
                c.id,
                c.name
   FROM company c
   INNER JOIN comp p
   ON p.id = c.parent_company_id)
SELECT comp.name
FROM comp;\end{verbatim}
\end{enumerate}

Of note here is query \emph{g} which implements a recursive query. Here the WITH operator is used to signify a Common Table Expression (CTE) - affectively a temporary table to be used for the duration of the query. The RECURSIVE operator is used to signify that the CTE is to be used recursively, and the UNION operator creates the recursive call by joining a select statement to the CTE (https://www.postgresql.org/docs/9.1/queries-with.html).

\section {Data Mining}

\subsection{Business Understanding}
The focus of this data mining activity is to predict the following two questions: Q1) Whether an acquisition is likely to succeed or fail Q2) If an acquisition is to succeed, how long will the process take?

 \subsection{Data Understanding}
The schema has almost certainly evolved since it was first designed. We must understand structural changes to the schema and data within the database, especially in the key tables, `company', `founder' and `acquisition'. Cardinality, sparseness and volume can aid us in understanding the data.

The original schema allowed NULL attributes which could impact on modelling. The attribute `acquisition.status' is used for both questions (either as a target attribute (Q1), or as an attribute to subset on (Q2)). For Q2 the target attribute is the delta \emph{d} := (`completion\_date' -` announced\_date').  We need to assess the quality and sparseness of these attributes. In the original schema `announced\_date' had a NOT NULL constraint; if this constraint has since been lifted both elements of our composite \emph{d} could be sparse.

We can now judge whether our data is sufficient to model on, or if enrichment with external data is required. Information omitted from the original schema includes industry sectors and financials. The schema may have evolved to include this information, however if not, we should consider finding relevant external data sources. This presents new complexity, including data ingestion and mapping companies to industry sectors whilst ensuring veracity.

 \subsection{Data Preparation}
The subset of completed acquisitions with NULL completed\_dates may require attention. If the subset is small (0-5\% of the superset) it may be acceptable to omit these records from the model, otherwise we may consider filling null values. Statistical methods i.e. using the mean delta /emph{d}, and adding this value to the announced\_date of each record could be considered. As this data forms a target attribute, filling the missing values from research may be more appropriate, though time and resource consuming.

 \subsection{Data Modelling}
Both cases use supervised learning methods. As Q1 is a binary classification problem a decision tree (DT) is a suitable model. Further data preparation may be required to aid modelling. For example, we could define a `hot' industry sector as one with high growth, or one which has seen voluminous acquisitions. Further decision points are formulated on company age, size and revenue.

 Q2 models a continuous numerical variable; making a regression model appropriate. Features modelled in Q1 can be reused, but from the subset of data containing only completed acquisitions.

 \subsection{Evaluation}
Binary classification problems use ROC curves to validate error rate. The models can be fine tuned using information gain and error reduction rate respectively.

We can also evaluate whether the models selected were appropriate. Could the DT be improved with a random forest algorithm? Perhaps the probability of an acquisition completing is of now interest (i.e. no longer a binary classification), in this instance we would restart the cycle, addressing structural questions of the data (e.g. is it acyclic) to define what probabilistic models can be applied.

\subsection{Deployment}
Whether the business are expecting a report or a deployable microservice will greatly affect the delivery. If the latter, does the organisation understand the maintenance burden as the schema evolves? If the former, then what is the update frequency of the research? Establishing these factors will inform the deployment strategy.


\end{document}
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
