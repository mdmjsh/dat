\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{\theenumi)}

\setlength{\parindent}{0pt}
\setlength{\parskip}{\baselineskip}

\title{Database Design}
\date{\today}

\begin{document}
\maketitle

\section{Relational Design}

\subsection{Relational schema design}
This section will discuss some of the noteworthy decisions taken in the design of the relational schema for the given problem domain.
The full SQL for the relational schema can be seen in \emph{appendix 1.1}. Note: PostgreSQL 9.6 is used for all DML and DDL defined in this document. The online SQL compiler \emph{https://rextester.com} was used to validate the schema and its constraints.

\subsubsection{Types}
The schema defines two custom enum types, namely  `ISO3166\_ALPHA2' (based on the ISO3166 standard), and `ACQUISITION\_STATUS'. It is worth noting that `ISO3166\_ALPHA2' is loaded with a subset of the full standard as this is fit for the purpose of our data model.

The ACQUISITION\_STATUS status enum is implement by the \emph{status} column in the \emp{acquisition} table, and the ISO3166\_ALPHA2 enum is implemented directly by the \emph{country} table as well as all tables which contain a foreign key to this (\emph{company}, \emph{founder}).

The use of Enums is advantageous as it provides a means of implicit santisation to the tables that implement these types. For example it means an \emph{acquisition} instance could never be created with an undesirable status (i.e a status outside the domain of strings defined by the enum). The same is true of the ISO3166\_ALPHA2 implementation, through it we can be assured the quality of the country code in the database is accurate. Considering Date's observation [2] that a table can be thought of as a predicate for which each row is a true proposition, custom data types enable us to constrain the table to only the domain of the predicate. For example, the ISO3166\_ALPHA2 implemented in this model it would be impossible to enter a country with the values `Norway', `NO' as the `NO' country code does not exist in the custom defined type.

It should be noted that the tuple (`Norway', `CN') would be a valid entry into the country table (as `CN' does exist in the custom type). We can verify that this record is false as per the ISO3166 standard as CN is the country code for China, however there is nothing wrong with it from the data storage level as defined by this schema. Therefore although implementing the custom type has helped, it has not guarantee the quality of the data. To frame ths in the context of propositional logic as prescribed by Date; it is possible for our schema to record false propositions. Dropping the country table altogether and extending the SO3166\_ALPHA2 type to include a country name and code tuple would therefore be a further improvement that could be made to this model if we wanted to introduce more rigour and reduce the error potential for such inaccuracies.

\subsubsection{Relational Schema Design}
For the given problem the following schema has been defined. \\

\begin{verbatim}
--PostgreSQL 9.6

CREATE TYPE ISO3166_ALPHA2 AS ENUM ( `DE', `FR', `GB', `US',
                                      `JP', `CN');


CREATE TYPE AQUISITION_STATUS AS ENUM ( `announced' `completed',
                                        `failed');

DROP TABLE IF EXISTS country CASCADE;
CREATE TABLE country ( name varchar (255) NOT NULL,
code ISO3166_ALPHA2 NOT NULL, PRIMARY KEY (code));


DROP TABLE IF EXISTS company;
CREATE TABLE company ( id serial, name varchar (255) NOT NULL,
founded date NOT NULL, country_code ISO3166_ALPHA2 NOT NULL,
parent_company_id int DEFAULT NULL,
-- need to make this an int not a serial to allow nulls
 -- Constraints
 PRIMARY KEY (id), CONSTRAINT company_name_country UNIQUE (name,
                                                   country_code),
                      FOREIGN KEY (country_code)
                      REFERENCES country (code),
                      FOREIGN KEY (parent_company_id)
                      REFERENCES company (id));


CREATE TABLE founder ( id serial, firstname varchar (255) NOT NULL,
                      lastname varchar (255) NOT NULL,
                      dob date NOT NULL,
                      country_of_origin ISO3166_ALPHA2 NOT NULL,
                      PRIMARY KEY (id),
                      FOREIGN KEY (country_of_origin)
                      REFERENCES country (code));


CREATE TABLE founder_companies( founder_id serial, company_id serial,
                               FOREIGN KEY (founder_id)
                               REFERENCES founder (id),
                               FOREIGN KEY (company_id)
                               REFERENCES company (id));


CREATE TABLE acquisition ( parent_company_id int NOT NULL,
                        child_company_id int NOT NULL,
                        status AQUISITION_STATUS,
                        price_usd NUMERIC DEFAULT NULL,
                        announced_date DATE NOT NULL,
                        completion_date DATE DEFAULT NULL,
                        FOREIGN KEY (parent_company_id)
                        REFERENCES company (id),
                        FOREIGN KEY (child_company_id)
                        REFERENCES company (id));

\end{verbatim}

\subsection{Normalisation}
A relational schema can be said to be compliant to BCNF if for all of its functional dependencies (x $\Rightarrow$ y) if one of the following statements is true:
 \begin{enumerate}
 \item \emph{y} is a subset of x (trivial functional dependency)
\item \emph{x} is a superkey (a subset of a candidate key for the relation). [5]
\end{enumerate}
Where a candidate key is a valiable key for identifying a row. Given this definition and with the non-trivial functional dependencies highlighted below, we can judge that this schema is compliant to BCNF - this is discussed in depth in the following sections.

\subsubsection{Company}

id $\Rightarrow${\{name, founded, country\_code, parent\_company\_id\}} \\
\{{name, country\_code\}} $\Rightarrow$ {\{founded, parent\_company\_id, id\}} \\

\\ N.B. At first glance a set of functional dependencies with \{{name,  founded}\} on the left side seems to exist, but this does not hold due to the composite unique constraint on name and country code (see \emph{section 1.2}).  That is to say that multiple companies with the same name can exist in the relation, provided they are in different countries. Hence functional dependencies with the \{{name, countrycode\}} tuple on the left side always hold, but those with \{{name, founded\}} will only hold in some data sets.

The \{{name, founded\}} tuple is candidate key. Had this been implemented as a composite primary key there would have been no requirement for the additional `id' attribute, however as this key is used in multiple tables as a foreign key (including the self referential foreign key`parent\_company\_id' in this table), it is more efficient to use a serial id field than a composite of two string columns. \emph{x} is a candidate key and therefore a superkey, hence this table does conform to BCNF.

\subsubsection{Founder}
id $\Rightarrow$ \{{firstname, lastname, dob, country\_of\_origin\}}\\

The only functional dependency present is the base dependency that all columns are functionally dependent on the `id' primary key. Whilst it initially appears that other dependencies may exist such as \\\\
\{{firstname, lastname\}} $\Rightarrow$ \{{dob, country\_of\_origin\}}\\\\
these dependencies are only temporal - i.e they hold for some states of the relation but not all [1]. As there are no unique constraints on any of these attributes, it is possible (if unlikely) to have founders with the same name, date of birth and country of origin in the relation (just as it is in the real world). \emph{x} is a primary key and therefore a superkey, hence this FD is BNCF compliant.

\subsubsection{Acquisition}
\{{parent\_company\_id, child\_company\_id\, announced\_date}\} $\Rightarrow${\{status, completion\_date}\} \\

This functional dependencies allows for historised records in the relation. Assuming that a parent company does not announce an attempted acquisition with the same child company more than once on the same day, if we know the attributes on the left side of the dependency we can always deduce the status and completion date of the acquisition. This enables historization, as a company could make multiple failed attempts to acquire another before they finally are successful. As with the company table, this combination could be used as a composite primary key and therefore we can evaluate this table is compliant to BCNF.

\subsubsection{Founder\_companies}
There are no functional dependencies as this is a many to many join table, i.e. a company can have many founders, and a founder can found many companies.

\subsection{Constraints}
The following constraints are expressed using Relational Calculus (RC) and then again in SQL.
\begin{enumerate}

  \item\label{part1}  RC:
 \begin{multline*}
   \{{id \mid \exists \ name, founded, country\_code, \\
   parent\_company\_id, (company(id, name, \\
   founded, country\_code, parent\_company\_id) \land \ id = parent\_company\_id)\}}
 \end{multline*}
 SQL:
 \begin{verbatim}
  ALTER TABLE company ADD CONSTRAINT not_own_parent
  CHECK (id != parent_company_id);
 \end{verbatim}

\item\label{part1}  RC:
  \begin{multline*}
  \{{(parent\_company\_id,  child\_company\_id) \mid \exists \ status, price\_usd, \\ announced\_date, completion\_date, (acquisition(parent\_company\_id, \\ child\_company\_id, status, price\_usd, announced\_date, completion\_date) \\ \land \ completion\_date < announced\_date )\}}
  \end{multline*}
 SQL: \begin{verbatim}
 ALTER TABLE acquisition ADD CONSTRAINT check_completion_date
 CHECK (completion_date >= announced_date);
 \end{verbatim}


 \item\label{part1}
 \begin{multline*}
 \{{(parent\_company\_id, child\_company\_id) \mid \exists \ status, price\_usd, announced\_date, \\
 completion\_date, (acquisition(parent\_company\_id, child\_company\_id, status, \\
 price\_usd, announced\_date, completion\_date)\\
 \land status \ \lnot \  `failed' \\
 \ \lor \ (status = `failed' \land completion\_date = completion\_date)  \}}
\end{multline*}
 \\ n.b. `completion\_date = completion\_date' is a means for asserting that the completion\_date value is not NULL. \\
  SQL: \begin{verbatim}
ALTER TABLE acquisition ADD CONSTRAINT CONSTRAINT
check_no_failed_completion_dates CHECK (
        status <> `failed'
        or status = `failed' AND (completion_date IS NULL))
);
\end{verbatim}


 \item\label{part1}
 \begin{multline*} RC:
 \{{id \mid \exists \ name, founded, country\_code, \\
 parent\_company\_id,  parent\_company\_id, child\_company\_id, \\
 status, price\_usd, announced\_date, completion\_date, \\
 (company(id, name, founded, country\_code, \\
 parent\_company\_id,  parent\_company\_id) \\
 \ \land \ acquisition(parent\_company\_id, child\_company\_id, \\
 status, price\_usd, announced\_date, completion\_date) \\
 \ \land \ announced\_date <  founded  \}}
 \end{multline*}
   SQL: This check cannot be enforced using SQL as a pure constraint, as it operates on values from multiple tables in the schema. It is possible to make use of a trigger which is called on row insert or update to check for the constraint and raise an exception should a write request attempt be found to be in violation. A potential implementation is:
 \begin{verbatim}

   CREATE FUNCTION acquisition_date_constraint() RETURNS trigger
   AS $acquisition_date_constraint$
    BEGIN
        IF NEW.announced_date < (SELECT founded FROM company
        WHERE id = NEW.child_company_id) THEN
            RAISE EXCEPTION
            `% Acquisition cannot be announced before
            company founded!', NEW.announced_date;
        END IF;

        RETURN NEW;
    END;
$acquisition_date_constraint$ LANGUAGE plpgsql;

-- Run the trigger whenever a row is
-- inserted or updated to acquisition
CREATE TRIGGER acquisition_date_constraint
BEFORE INSERT OR UPDATE ON acquisition
    FOR EACH ROW EXECUTE PROCEDURE acquisition_date_constraint();
   \end{verbatim}
\end{enumerate}
Here the custom function \emph{acquisition\_date\_constraint} is defined to return a trigger. The trigger uses SQL a SELECT statement and the NEW keyword to compare the ingress announced date and comparing it to the founded date of the company. An exception is raised if the constraint is violated. The function is set to be called on any insert or update to the acquisition table. [4]

\section{Relations - Relational Calculus \& Algebra}
All of the queries in this section are expressed using Relational Algebra (RA), except for \emph{query a} is expressed using Relational Calculus (RC).
 \begin{enumerate}

 \item\label{part1}\begin{multline*}
 \{{id \mid \exists \ name, founded, country\_code, parent\_company\_id, \\ (company(id, name, founded, country\_code, parent\_company\_id) \\
  \land \ founded \ > \ `1999-12-31')\}}
 \end{multline*}
  \item\label{part1}\begin{multline*}
  \pi \ id (\sigma \ country\_code = `US' \ \lor country\_code = `GB' (company))
 \end{multline*}

  \item\label{part1}\begin{displaymath}
  \pi \ parent\_company\_id (\sigma status \ = `completed' (acquisition))
 \end{displaymath}
 n.b. The SQL equivalent to this query (see \emph {section 3}) uses the DISTINCT operator to remove duplicates; as RA is based on set theory there are no duplicates.

  \item\label{part1}\begin{multline*} \pi \ founder\_id (\sigma founder\_id \geq 3 (founder\_id \ \\
  g \ count (founder\_id) (founder\_companies))
 \end{multline*}
 n.b. Here the aggregate operator \emph{g} is used to count over the occurrences of each founder\_id in the relational. This aggregate can then be selected over.
  \item\label{part1}\begin{multline*}
  \pi \ child\_company\_id (f \bowtie c \ with (f := \\
  (\pi \ child\_company\_id, announced\_date (\sigma \ status = `failed' (acquisition))) \\
  c := (\pi \ child\_company\_id, completion\_date \\
  (\sigma \ status = `completed' (acquisition)))
  ) \\
  \sigma completion\_date > announced\_date)
 \end{multline*}
 In this query we select all companies with a failed acquisition and completed acquisitions and name the resulting relations \emph{f} \& \emph{c} respectively using the \emph{with} operator. In both relations the \emph{child\_company\_id} is kept. Within \emph{f} the \emph{announced\_date} attribute is kept, and within {c} the \emph{completion\_date} attribute is kept. The rest of the fields are projected away. The relations are then joined using a natural join which utilises the fact that both relations have a \emph{child\_company\_id} attribute.We can then compare the \emph{completion\_date} of \emph{c} to the \emph{announced\_date} of \emph{f} to select only those in which the completed acquisition occurred after the failed attempt.

 It is worth noting that this query assumes that the acquisitions are announced and resolved (i.e. fail or complete) in contiguous manner in respect of their announced dates. The schema does not record the \emph {failed\_date} for failed acquisitions. Such an addition would make this query more accurate as the completion and failed dates could be directly compared (as oppossed to comparing the announced\_date and completion\_date).  This would significantly affect the database design as the additional attribute were to be added to the acquisitions relation then new functional dependencies would be introduced which would cause third normal form (3NF) violations. For example, \{{announced\_date, status, parent\_company\_id, child\_company\_id }\} $\Rightarrow$ \{{completion\_date, failed\_date}\} or simply \{{completion\_date $\Leftrightarrow$ failed\_date}\}. Both of these examples are 3NF violations and as both introduce functional dependencies between non-key attributes.

To strictly keep the schema in 3NF/BCNF a potential refactor could be to have an aqcuisition\_dates table with just an announced\_date and end\_date. The acquisitions table could then have a FK to this table as well as the status as is currently indicated. Implementing this design was outside of the scope of the project requirements, but it is interesting to note that even adding one field in the aim of better analysis can drastically affect the normalisation of the database.

  \item\label{part1} This query is not expressible in RA or RC due to the lack of a native \emph{limit} function.
  \item\label{part1} This query is not expressible in RA or RC due to the lack of recursion in the query languages.
  \end{enumerate}



\section{SQL}
\begin{enumerate}

 \item\label{part1}\begin{verbatim}SELECT id
FROM company
WHERE founded > `1999-12-31';\end{verbatim}

  \item\label{part1}\begin{verbatim}SELECT id
FROM company
WHERE country_code IN (`UK', `US');\end{verbatim}
  \item\label{part1}\begin{verbatim}SELECT distinct(parent_company_id)
FROM acquisition
WHERE status = `completed';\end{verbatim}
  \item\label{part1}\begin{verbatim} SELECT founder_id,
       COUNT (founder_id)
FROM founder_companies
GROUP BY founder_id HAVING COUNT(founder_id) >= 3;\end{verbatim}
  \item\label{part1}\begin{verbatim}SELECT f.child_company_id
FROM
  (SELECT *
   FROM acquisition
   WHERE status = `failed')f
JOIN
  (SELECT *
   FROM acquisition
   WHERE status = `completed')c
   ON c.child_company_id = f.child_company_id
WHERE c.completion_date > f.failed_date;\end{verbatim}
  \item\label{part1}\begin{verbatim}SELECT founder_id,
       count(founder_id)
FROM founder_companies
GROUP BY founder_id
ORDER BY count(founder_id) DESC LIMIT 10 ;\end{verbatim}
  \item\label{part1}\begin{verbatim}WITH RECURSIVE comp AS
  (SELECT parent_company_id,
          id,
          name
   FROM company
   WHERE name = `Tesla'
   UNION SELECT c.parent_company_id,
                c.id,
                c.name
   FROM company c
   INNER JOIN comp p
   ON p.id = c.parent_company_id)
SELECT comp.name
FROM comp;\end{verbatim}
\end{enumerate}

Of note here is query \emph{(g)} which implements a recursive query. Here the \emph{WITH} operator is used to signify a Common Table Expression (CTE) - affectively a temporary table to be used for the duration of the query. The \emph{RECURSIVE} operator is used to signify that the CTE is to be used recursively, and the UNION operator creates the recursive call by joining a SELECT statement to the CTE [3].

\section {Data Mining}

The focus of this data mining activity is to predict the following two questions: Q1) Whether an acquisition is likely to succeed or fail Q2) If an acquisition is to succeed, how long will the process take?

 \subsection{Data Understanding}
The schema has almost certainly evolved since it was first designed. We must understand structural changes to the schema and data within the database, especially in the key tables, `company', `founder' and `acquisition'. Cardinality, sparseness and volume can aid us in understanding the data.

The original schema allowed NULL attributes which could impact on modelling. The attribute `acquisition.status' is used for both questions (either as a target attribute (Q1), or as an attribute to subset on (Q2)). For Q2 the target attribute is the delta \emph{d} := (`completion\_date' -` announced\_date').  We need to assess the quality and sparseness of these attributes. In the original schema `announced\_date' had a NOT NULL constraint; if this constraint has since been lifted both elements of our composite \emph{d} could be sparse.

We can now judge whether our data is sufficient to model on, or if enrichment with external data is required. Information omitted from the original schema includes industry sectors and financials. The schema may have evolved to include this information, however if not, we should consider finding relevant external data sources. This presents new complexity, including data ingestion and mapping companies to industry sectors whilst ensuring veracity.

 \subsection{Data Preparation}
The subset of completed acquisitions with NULL completed\_dates may require attention. If the subset is small (0-5\% of the superset) it may be acceptable to omit these records from the model, otherwise we may consider filling null values. Statistical methods i.e. using the mean delta /emph{d}, and adding this value to the announced\_date of each record could be considered. As this data forms a target attribute, filling the missing values from research may be more appropriate, though time and resource consuming.

 \subsection{Data Modelling}
Both cases use supervised learning methods. As Q1 is a binary classification problem a decision tree (DT) is a suitable model. Further data preparation may be required to aid modelling. For example, we could define a `hot' industry sector as one with high growth, or one which has seen voluminous acquisitions. Further decision points are formulated on company age, size and revenue.

 Q2 models a continuous numerical variable; making a regression model appropriate. Features modelled in Q1 can be reused, but from the subset of data containing only completed acquisitions.

 \subsection{Evaluation}
Binary classification problems use ROC curves to validate error rate. The models can be fine tuned using information gain and error reduction rate respectively.

We can also evaluate whether the models selected were appropriate. Could the DT be improved with a random forest algorithm? Perhaps the probability of an acquisition completing is of now interest (i.e. no longer a binary classification), in this instance we would restart the cycle, addressing structural questions of the data (e.g. is it acyclic) to define what probabilistic models can be applied.

\subsection{Deployment}
Whether the business are expecting a report or a deployable microservice will greatly affect the delivery. If the latter, does the organisation understand the maintenance burden as the schema evolves? If the former, then what is the update frequency of the research? Establishing these factors will inform the deployment strategy.
\begin{thebibliography}{9}

\bibitem{date}
Date, C.J
\textit{An Introduction to Database Systems}.
(2003). An Introduction to Database Systems. 8th ed. London: Pearson. 334-336

\bibitem{date}
Date, C.J
\textit{An Introduction to Database Systems}.
(2003). An Introduction to Database Systems. 8th ed. London: Pearson. 783-789

\bibitem{triggers}
PostgreSQL documentation. (2016).
\textit{Triggers on Data Changes}
 Available: https://www.postgresql.org/docs/9.6/plpgsql-trigger.html#PLPGSQL-TRIGGER-EXAMPLE. [Accessed 6th Jan 2019.]

\bibitem{withqueries}
PostgreSQL. (2016). \textit{WITH Queries (Common Table Expressions).} Available: https://www.postgresql.org/docs/9.6/queries-with.html. [Accessed 6th Jan 2019.]

\bibitem{Kozubek}
Agnieszka Kozubek. (2014). \textit{The Boyce-Codd Normal Form (BCNF).} Available: https://www.vertabelo.com/blog/technical-articles/boyce-codd-normal-form-bcnf. [Accessed 6th Jan 2019.]


\end{thebibliography}

\end{document}
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
